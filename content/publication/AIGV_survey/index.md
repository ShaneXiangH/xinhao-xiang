---
abstract: The growing capabilities of AI in generating video content have brought forward significant challenges in effectively evaluating these videos. Unlike static images or text, video content involves complex spatial and temporal dynamics which may require a more comprehensive and systematic evaluation of its contents in aspects like video presentation quality, semantic information delivery, alignment with human intentions, and the virtual-reality consistency with our physical world. This survey identifies the emerging field of AI-Generated Video Evaluation (AIGVE), highlighting the importance of assessing how well AI-generated videos align with human perception and meet specific instructions. We provide a structured analysis of existing methodologies that could be potentially used to evaluate AI-generated videos. By outlining the strengths and gaps in current approaches, we advocate for the development of more robust and nuanced evaluation frameworks that can handle the complexities of video content, which include not only the conventional metric-based evaluations, but also the current human-involved evaluations, and the future model-centered evaluations. This survey aims to establish a foundational knowledge base for both researchers from academia and practitioners from the industry, facilitating the future advancement of evaluation methods for AI-generated video content.
# slides: example
# url_pdf: "https://downloads.hindawi.com/journals/complexity/2020/8863526.pdf"

# publication_types:
#   - "Preprint"
authors:
  - Xiao Liu
  - Xinhao Xiang
  - Zizhong Li
  - Yongheng Wang
  - Zhuoheng Li
  - Zhuosheng Liu
  - Weidi Zhang
  - Weiqi Ye
  - Jiawei Zhang
author_notes:
  - Xiao Liu
  - Xinhao Xiang
  - and Zizhong Li contributed equally to this work
publication_types:
  - "Preprint"
summary: "A comprehensive review of current methodologies of AI-Generated Video Evaluation (AIGVE), highlighting emerging field, and guiding for future research directions."

url_dataset: ""
url_project: ""
publication_short: ""
url_source: ""
#url_video: "https://drive.google.com/file/d/1-4rLMaELwzTadFjY1JglA715cdTOvUFk/view?usp=sharing"
title: "A Survey of AI-Generated Video Evaluation"
# doi: https://doi.org/10.1155/2020/8863526
featured: false
url_pdf: "https://arxiv.org/abs/2410.19884"

tags: []
# projects:
#   - SUSTech
# image:
#   caption: "Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)"
#   focal_point: ""
#   preview_only: false
date: 2024-09-16T04:39:21.092Z

url_slides: ""
# publishDate: 2020-11-29T04:39:21.092Z
url_poster: ""
# url_code: "https://github.com/ShaneXiangH/E2RPSO"
---

<!-- {{% callout note %}}
Click the *Cite* button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}} -->

<!-- Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). -->
